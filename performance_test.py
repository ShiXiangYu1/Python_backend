#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
æ€§èƒ½æµ‹è¯•è„šæœ¬

ç”¨äºæµ‹è¯•APIçš„æ€§èƒ½ï¼ŒåŒ…æ‹¬å“åº”æ—¶é—´ã€å¹¶å‘å¤„ç†èƒ½åŠ›ã€æ•°æ®åº“æ€§èƒ½ç­‰ã€‚
"""

import json
import time
import asyncio
import statistics
import aiohttp
import matplotlib.pyplot as plt
import numpy as np
from datetime import datetime
import psutil
import platform
import os
import csv

# æµ‹è¯•é…ç½®
BASE_URL = "http://localhost:8000"
API_PREFIX = "/api/v1"
TEST_USER = {"username": "sxy", "password": "sxy123456"}
RESULTS = {}
TOKEN = None
MAX_CONCURRENT_REQUESTS = 50
REQUEST_COUNT = 200
TEST_ENDPOINTS = [
    {"name": "è·å–å½“å‰ç”¨æˆ·", "method": "GET", "path": "/users/me", "auth_required": True},
    {"name": "è·å–AIæ¨¡å‹åˆ—è¡¨", "method": "GET", "path": "/models", "auth_required": True},
    {"name": "å¥åº·æ£€æŸ¥", "method": "GET", "path": "/health", "auth_required": False},
]
CSV_RESULT_FILE = "performance_results.csv"
CHART_RESULT_FILE = "performance_results.png"
REPORT_FILE = "performance_report.md"

async def login():
    """ç™»å½•å¹¶è·å–è®¤è¯ä»¤ç‰Œ"""
    global TOKEN
    async with aiohttp.ClientSession() as session:
        try:
            async with session.post(
                f"{BASE_URL}{API_PREFIX}/auth/login/json",
                json=TEST_USER,
                headers={"Content-Type": "application/json"}
            ) as response:
                if response.status == 200:
                    data = await response.json()
                    TOKEN = data.get("access_token")
                    print(f"âœ… ç™»å½•æˆåŠŸï¼Œè·å–åˆ°ä»¤ç‰Œ")
                    return True
                else:
                    print(f"âŒ ç™»å½•å¤±è´¥: {response.status}")
                    return False
        except Exception as e:
            print(f"âŒ ç™»å½•è¿‡ç¨‹å‘ç”Ÿé”™è¯¯: {str(e)}")
            return False

async def make_request(session, endpoint, request_id):
    """å‘é€å•ä¸ªè¯·æ±‚ï¼Œå¹¶è®°å½•æ€§èƒ½æŒ‡æ ‡"""
    method = endpoint["method"]
    path = endpoint["path"]
    auth_required = endpoint["auth_required"]
    url = f"{BASE_URL}{API_PREFIX}{path}"
    
    headers = {}
    if auth_required and TOKEN:
        headers["Authorization"] = f"Bearer {TOKEN}"
    
    start_time = time.time()
    try:
        if method == "GET":
            async with session.get(url, headers=headers) as response:
                response_time = time.time() - start_time
                status = response.status
                try:
                    # å°è¯•è¯»å–å“åº”ä½“çš„å¤§å°
                    response_data = await response.read()
                    size = len(response_data)
                except:
                    size = 0
                
                return {
                    "request_id": request_id,
                    "endpoint": endpoint["name"],
                    "status_code": status,
                    "response_time": response_time,
                    "size": size,
                    "success": 200 <= status < 400
                }
        elif method == "POST":
            async with session.post(url, headers=headers) as response:
                response_time = time.time() - start_time
                status = response.status
                try:
                    response_data = await response.read()
                    size = len(response_data)
                except:
                    size = 0
                
                return {
                    "request_id": request_id,
                    "endpoint": endpoint["name"],
                    "status_code": status,
                    "response_time": response_time,
                    "size": size,
                    "success": 200 <= status < 400
                }
    except Exception as e:
        response_time = time.time() - start_time
        return {
            "request_id": request_id,
            "endpoint": endpoint["name"],
            "status_code": 0,
            "response_time": response_time,
            "size": 0,
            "success": False,
            "error": str(e)
        }

async def run_load_test(endpoint, concurrency, request_count):
    """æ‰§è¡Œè´Ÿè½½æµ‹è¯•ï¼Œå¹¶æ”¶é›†ç»“æœ"""
    print(f"\nâš¡ æµ‹è¯•ç«¯ç‚¹: {endpoint['name']} (å¹¶å‘æ•°: {concurrency}, è¯·æ±‚æ•°: {request_count})")
    
    all_results = []
    semaphore = asyncio.Semaphore(concurrency)
    
    async def bounded_request(session, endpoint, request_id):
        async with semaphore:
            return await make_request(session, endpoint, request_id)
    
    async with aiohttp.ClientSession() as session:
        tasks = [bounded_request(session, endpoint, i) for i in range(request_count)]
        results = await asyncio.gather(*tasks)
        all_results.extend(results)
    
    # åˆ†æç»“æœ
    response_times = [r["response_time"] for r in all_results if r["success"]]
    successful_requests = sum(1 for r in all_results if r["success"])
    failed_requests = sum(1 for r in all_results if not r["success"])
    
    if response_times:
        avg_response_time = statistics.mean(response_times)
        median_response_time = statistics.median(response_times)
        min_response_time = min(response_times)
        max_response_time = max(response_times)
        p95_response_time = np.percentile(response_times, 95) if len(response_times) > 10 else max_response_time
        
        # è®¡ç®—æ¯ç§’è¯·æ±‚æ•° (RPS)
        total_duration = max(response_times) - min(response_times) if len(response_times) > 1 else sum(response_times)
        rps = len(response_times) / total_duration if total_duration > 0 else 0
        
        print(f"âœ… æˆåŠŸè¯·æ±‚: {successful_requests}/{request_count} ({successful_requests/request_count*100:.2f}%)")
        print(f"âŒ å¤±è´¥è¯·æ±‚: {failed_requests}/{request_count} ({failed_requests/request_count*100:.2f}%)")
        print(f"â±ï¸ å¹³å‡å“åº”æ—¶é—´: {avg_response_time*1000:.2f}ms")
        print(f"â±ï¸ ä¸­ä½æ•°å“åº”æ—¶é—´: {median_response_time*1000:.2f}ms")
        print(f"â±ï¸ æœ€çŸ­å“åº”æ—¶é—´: {min_response_time*1000:.2f}ms")
        print(f"â±ï¸ æœ€é•¿å“åº”æ—¶é—´: {max_response_time*1000:.2f}ms")
        print(f"â±ï¸ 95%å“åº”æ—¶é—´: {p95_response_time*1000:.2f}ms")
        print(f"ğŸš€ æ¯ç§’è¯·æ±‚æ•° (RPS): {rps:.2f}")
        
        return {
            "endpoint": endpoint["name"],
            "concurrency": concurrency,
            "request_count": request_count,
            "successful_requests": successful_requests,
            "failed_requests": failed_requests,
            "success_rate": successful_requests / request_count if request_count > 0 else 0,
            "avg_response_time": avg_response_time,
            "median_response_time": median_response_time,
            "min_response_time": min_response_time,
            "max_response_time": max_response_time,
            "p95_response_time": p95_response_time,
            "rps": rps,
            "detailed_results": all_results
        }
    else:
        print(f"âŒ æ‰€æœ‰è¯·æ±‚å‡å¤±è´¥")
        return {
            "endpoint": endpoint["name"],
            "concurrency": concurrency,
            "request_count": request_count,
            "successful_requests": 0,
            "failed_requests": failed_requests,
            "success_rate": 0,
            "avg_response_time": 0,
            "median_response_time": 0,
            "min_response_time": 0,
            "max_response_time": 0,
            "p95_response_time": 0,
            "rps": 0,
            "detailed_results": all_results
        }

async def monitor_system_resources(duration, interval=1):
    """ç›‘æ§ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ"""
    print(f"\nğŸ“Š å¼€å§‹ç›‘æ§ç³»ç»Ÿèµ„æº (æŒç»­ {duration} ç§’, é—´éš” {interval} ç§’)...")
    
    cpu_percentages = []
    memory_usages = []
    timestamps = []
    
    end_time = time.time() + duration
    while time.time() < end_time:
        # æ”¶é›†CPUä½¿ç”¨ç‡
        cpu_percent = psutil.cpu_percent(interval=0.1)
        cpu_percentages.append(cpu_percent)
        
        # æ”¶é›†å†…å­˜ä½¿ç”¨æƒ…å†µ
        memory = psutil.virtual_memory()
        memory_usage = memory.percent
        memory_usages.append(memory_usage)
        
        timestamps.append(time.time())
        
        print(f"CPU: {cpu_percent}% | RAM: {memory_usage}%")
        
        # ç­‰å¾…
        await asyncio.sleep(interval)
    
    return {
        "timestamps": timestamps,
        "cpu_percentages": cpu_percentages,
        "memory_usages": memory_usages,
        "avg_cpu": statistics.mean(cpu_percentages) if cpu_percentages else 0,
        "max_cpu": max(cpu_percentages) if cpu_percentages else 0,
        "avg_memory": statistics.mean(memory_usages) if memory_usages else 0,
        "max_memory": max(memory_usages) if memory_usages else 0
    }

async def test_endpoint_scaling(endpoint):
    """æµ‹è¯•ç«¯ç‚¹åœ¨ä¸åŒå¹¶å‘çº§åˆ«ä¸‹çš„æ€§èƒ½è¡¨ç°"""
    print(f"\nğŸ“ˆ æµ‹è¯•ç«¯ç‚¹åœ¨ä¸åŒå¹¶å‘çº§åˆ«ä¸‹çš„è¡¨ç°: {endpoint['name']}")
    
    results = []
    concurrency_levels = [1, 5, 10, 20, 50]
    
    for concurrency in concurrency_levels:
        request_count = concurrency * 10
        result = await run_load_test(endpoint, concurrency, request_count)
        results.append(result)
    
    return results

async def test_response_time_stability(endpoint, requests=50, concurrency=10):
    """æµ‹è¯•å“åº”æ—¶é—´çš„ç¨³å®šæ€§"""
    print(f"\nğŸ” æµ‹è¯•å“åº”æ—¶é—´ç¨³å®šæ€§: {endpoint['name']}")
    
    result = await run_load_test(endpoint, concurrency, requests)
    
    if result["successful_requests"] > 0:
        # è®¡ç®—å“åº”æ—¶é—´çš„æ ‡å‡†å·®
        response_times = [r["response_time"] for r in result["detailed_results"] if r["success"]]
        if len(response_times) > 1:
            std_dev = statistics.stdev(response_times)
            cv = (std_dev / result["avg_response_time"]) * 100 if result["avg_response_time"] > 0 else 0
            
            print(f"ğŸ“Š å“åº”æ—¶é—´æ ‡å‡†å·®: {std_dev*1000:.2f}ms")
            print(f"ğŸ“Š å˜å¼‚ç³»æ•°: {cv:.2f}%")
            
            stability_rating = ""
            if cv < 10:
                stability_rating = "æä½³"
            elif cv < 20:
                stability_rating = "è‰¯å¥½"
            elif cv < 30:
                stability_rating = "ä¸€èˆ¬"
            elif cv < 50:
                stability_rating = "ä¸ç¨³å®š"
            else:
                stability_rating = "æä¸ç¨³å®š"
                
            print(f"ğŸ“Š ç¨³å®šæ€§è¯„çº§: {stability_rating}")
            
            result["std_dev"] = std_dev
            result["cv"] = cv
            result["stability_rating"] = stability_rating
        else:
            print("âŒ æ ·æœ¬é‡ä¸è¶³ï¼Œæ— æ³•è®¡ç®—æ ‡å‡†å·®")
    else:
        print("âŒ æ²¡æœ‰æˆåŠŸçš„è¯·æ±‚ï¼Œæ— æ³•è¯„ä¼°ç¨³å®šæ€§")
    
    return result

def generate_performance_charts(results):
    """ç”Ÿæˆæ€§èƒ½æµ‹è¯•å›¾è¡¨"""
    print("\nğŸ“Š ç”Ÿæˆæ€§èƒ½æµ‹è¯•å›¾è¡¨...")
    
    plt.figure(figsize=(15, 10))
    
    # åˆ›å»º2x2çš„å­å›¾
    ax1 = plt.subplot(2, 2, 1)
    ax2 = plt.subplot(2, 2, 2)
    ax3 = plt.subplot(2, 2, 3)
    ax4 = plt.subplot(2, 2, 4)
    
    # 1. å“åº”æ—¶é—´æ¯”è¾ƒ
    endpoints = []
    avg_times = []
    p95_times = []
    
    for endpoint_name, endpoint_results in results["endpoint_results"].items():
        endpoints.append(endpoint_name)
        avg_times.append(endpoint_results["avg_response_time"] * 1000)  # è½¬æ¢ä¸ºæ¯«ç§’
        p95_times.append(endpoint_results["p95_response_time"] * 1000)  # è½¬æ¢ä¸ºæ¯«ç§’
    
    x = np.arange(len(endpoints))
    width = 0.35
    
    ax1.bar(x - width/2, avg_times, width, label='å¹³å‡å“åº”æ—¶é—´')
    ax1.bar(x + width/2, p95_times, width, label='95%å“åº”æ—¶é—´')
    ax1.set_ylabel('å“åº”æ—¶é—´ (ms)')
    ax1.set_title('å„ç«¯ç‚¹å“åº”æ—¶é—´æ¯”è¾ƒ')
    ax1.set_xticks(x)
    ax1.set_xticklabels(endpoints, rotation=30, ha='right')
    ax1.legend()
    ax1.grid(True, linestyle='--', alpha=0.7)
    
    # 2. æ¯ç§’è¯·æ±‚æ•°æ¯”è¾ƒ
    rps_values = [results["endpoint_results"][endpoint]["rps"] for endpoint in endpoints]
    
    ax2.bar(endpoints, rps_values, color='orange')
    ax2.set_ylabel('è¯·æ±‚/ç§’')
    ax2.set_title('å„ç«¯ç‚¹æ¯ç§’å¤„ç†è¯·æ±‚æ•°')
    ax2.set_xticklabels(endpoints, rotation=30, ha='right')
    ax2.grid(True, linestyle='--', alpha=0.7)
    
    # 3. æˆåŠŸç‡æ¯”è¾ƒ
    success_rates = [results["endpoint_results"][endpoint]["success_rate"] * 100 for endpoint in endpoints]
    
    ax3.bar(endpoints, success_rates, color='green')
    ax3.set_ylabel('æˆåŠŸç‡ (%)')
    ax3.set_title('å„ç«¯ç‚¹è¯·æ±‚æˆåŠŸç‡')
    ax3.set_xticklabels(endpoints, rotation=30, ha='right')
    ax3.set_ylim(0, 100)
    ax3.grid(True, linestyle='--', alpha=0.7)
    
    # 4. ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ
    if "system_resources" in results:
        resources = results["system_resources"]
        time_points = range(len(resources["cpu_percentages"]))
        
        ax4.plot(time_points, resources["cpu_percentages"], label='CPUä½¿ç”¨ç‡', color='red')
        ax4.plot(time_points, resources["memory_usages"], label='å†…å­˜ä½¿ç”¨ç‡', color='blue')
        ax4.set_xlabel('æ—¶é—´ (ç§’)')
        ax4.set_ylabel('ä½¿ç”¨ç‡ (%)')
        ax4.set_title('ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ')
        ax4.legend()
        ax4.grid(True, linestyle='--', alpha=0.7)
        ax4.set_ylim(0, 100)
    
    plt.tight_layout()
    plt.savefig(CHART_RESULT_FILE)
    print(f"âœ… å·²ç”Ÿæˆå›¾è¡¨: {CHART_RESULT_FILE}")

def export_to_csv(results):
    """å°†æ€§èƒ½æµ‹è¯•ç»“æœå¯¼å‡ºä¸ºCSVæ–‡ä»¶"""
    print(f"\nğŸ“Š å¯¼å‡ºæµ‹è¯•ç»“æœåˆ°CSV: {CSV_RESULT_FILE}")
    
    with open(CSV_RESULT_FILE, 'w', newline='', encoding='utf-8') as csvfile:
        fieldnames = [
            'endpoint', 'concurrency', 'request_count', 'successful_requests', 
            'failed_requests', 'success_rate', 'avg_response_time_ms', 
            'median_response_time_ms', 'min_response_time_ms', 'max_response_time_ms', 
            'p95_response_time_ms', 'rps'
        ]
        
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        writer.writeheader()
        
        for endpoint_name, endpoint_result in results["endpoint_results"].items():
            writer.writerow({
                'endpoint': endpoint_name,
                'concurrency': endpoint_result.get('concurrency', ''),
                'request_count': endpoint_result.get('request_count', ''),
                'successful_requests': endpoint_result.get('successful_requests', 0),
                'failed_requests': endpoint_result.get('failed_requests', 0),
                'success_rate': f"{endpoint_result.get('success_rate', 0) * 100:.2f}%",
                'avg_response_time_ms': f"{endpoint_result.get('avg_response_time', 0) * 1000:.2f}",
                'median_response_time_ms': f"{endpoint_result.get('median_response_time', 0) * 1000:.2f}",
                'min_response_time_ms': f"{endpoint_result.get('min_response_time', 0) * 1000:.2f}",
                'max_response_time_ms': f"{endpoint_result.get('max_response_time', 0) * 1000:.2f}",
                'p95_response_time_ms': f"{endpoint_result.get('p95_response_time', 0) * 1000:.2f}",
                'rps': f"{endpoint_result.get('rps', 0):.2f}"
            })
    
    print(f"âœ… å·²å¯¼å‡ºCSVæ–‡ä»¶: {CSV_RESULT_FILE}")

def generate_performance_report(results):
    """ç”Ÿæˆæ€§èƒ½æµ‹è¯•æŠ¥å‘Š"""
    print(f"\nğŸ“Š ç”Ÿæˆæ€§èƒ½æµ‹è¯•æŠ¥å‘Š: {REPORT_FILE}")
    
    with open(REPORT_FILE, 'w', encoding='utf-8') as f:
        f.write("# APIæ€§èƒ½æµ‹è¯•æŠ¥å‘Š\n\n")
        
        # å†™å…¥æµ‹è¯•ä¿¡æ¯
        f.write("## æµ‹è¯•ä¿¡æ¯\n\n")
        f.write(f"- **æµ‹è¯•æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"- **æµ‹è¯•ç¯å¢ƒ**: {platform.system()} {platform.release()}\n")
        f.write(f"- **å¤„ç†å™¨**: {platform.processor()}\n")
        f.write(f"- **Pythonç‰ˆæœ¬**: {platform.python_version()}\n")
        f.write(f"- **æµ‹è¯•ç«¯ç‚¹æ•°**: {len(results['endpoint_results'])}\n")
        f.write(f"- **æœ€å¤§å¹¶å‘æ•°**: {MAX_CONCURRENT_REQUESTS}\n\n")
        
        # å†™å…¥æ€»ä½“æ€§èƒ½è¯„ä¼°
        f.write("## æ€»ä½“æ€§èƒ½è¯„ä¼°\n\n")
        
        # è®¡ç®—å¹³å‡å“åº”æ—¶é—´å’Œå¹³å‡RPS
        avg_response_times = [endpoint_result["avg_response_time"] for endpoint_result in results["endpoint_results"].values()]
        avg_rps = [endpoint_result["rps"] for endpoint_result in results["endpoint_results"].values()]
        
        overall_avg_response_time = statistics.mean(avg_response_times) if avg_response_times else 0
        overall_avg_rps = statistics.mean(avg_rps) if avg_rps else 0
        
        # æ€§èƒ½è¯„çº§
        performance_score = 0
        if overall_avg_response_time > 0:
            response_time_score = min(100, 100 / (overall_avg_response_time * 10)) 
            rps_score = min(100, overall_avg_rps * 2)
            performance_score = (response_time_score + rps_score) / 2
        
        if performance_score >= 90:
            performance_rating = "A (ä¼˜ç§€)"
            recommendation = "ç³»ç»Ÿæ€§èƒ½è¡¨ç°ä¼˜ç§€ï¼Œå¯ä»¥è€ƒè™‘è¿›ä¸€æ­¥ä¼˜åŒ–ç¼“å­˜ç­–ç•¥å’Œæ•°æ®åº“æŸ¥è¯¢ã€‚"
        elif performance_score >= 80:
            performance_rating = "B (è‰¯å¥½)"
            recommendation = "ç³»ç»Ÿæ•´ä½“æ€§èƒ½è‰¯å¥½ï¼Œä½†éƒ¨åˆ†ç«¯ç‚¹å“åº”æ—¶é—´å¯èƒ½éœ€è¦ä¼˜åŒ–ã€‚"
        elif performance_score >= 70:
            performance_rating = "C (ä¸€èˆ¬)"
            recommendation = "ç³»ç»Ÿæ€§èƒ½ä¸€èˆ¬ï¼Œéœ€è¦ç€é‡ä¼˜åŒ–æ…¢æŸ¥è¯¢å’Œå¹¶å‘å¤„ç†èƒ½åŠ›ã€‚"
        elif performance_score >= 60:
            performance_rating = "D (è¾ƒå·®)"
            recommendation = "ç³»ç»Ÿæ€§èƒ½è¾ƒå·®ï¼Œå­˜åœ¨æ˜æ˜¾çš„ç“¶é¢ˆï¼Œéœ€è¦è¿›è¡Œå…¨é¢ä¼˜åŒ–ã€‚"
        else:
            performance_rating = "F (ä¸åŠæ ¼)"
            recommendation = "ç³»ç»Ÿæ€§èƒ½æå·®ï¼Œå»ºè®®é‡æ„æ¶æ„æˆ–å…³é”®ç»„ä»¶ã€‚"
        
        f.write(f"- **å¹³å‡å“åº”æ—¶é—´**: {overall_avg_response_time*1000:.2f}ms\n")
        f.write(f"- **å¹³å‡æ¯ç§’è¯·æ±‚æ•°**: {overall_avg_rps:.2f}\n")
        f.write(f"- **æ€§èƒ½è¯„çº§**: {performance_rating}\n")
        f.write(f"- **æ€§èƒ½å¾—åˆ†**: {performance_score:.2f}/100\n")
        f.write(f"- **å»ºè®®**: {recommendation}\n\n")
        
        # å†™å…¥ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ
        if "system_resources" in results:
            f.write("## ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ\n\n")
            resources = results["system_resources"]
            
            f.write(f"- **å¹³å‡CPUä½¿ç”¨ç‡**: {resources['avg_cpu']:.2f}%\n")
            f.write(f"- **æœ€å¤§CPUä½¿ç”¨ç‡**: {resources['max_cpu']:.2f}%\n")
            f.write(f"- **å¹³å‡å†…å­˜ä½¿ç”¨ç‡**: {resources['avg_memory']:.2f}%\n")
            f.write(f"- **æœ€å¤§å†…å­˜ä½¿ç”¨ç‡**: {resources['max_memory']:.2f}%\n\n")
        
        # å†™å…¥å„ç«¯ç‚¹æ€§èƒ½è¯¦æƒ…
        f.write("## å„ç«¯ç‚¹æ€§èƒ½è¯¦æƒ…\n\n")
        
        for endpoint_name, endpoint_result in results["endpoint_results"].items():
            f.write(f"### {endpoint_name}\n\n")
            
            f.write(f"- **è¯·æ±‚æˆåŠŸç‡**: {endpoint_result['success_rate']*100:.2f}%\n")
            f.write(f"- **å¹³å‡å“åº”æ—¶é—´**: {endpoint_result['avg_response_time']*1000:.2f}ms\n")
            f.write(f"- **ä¸­ä½æ•°å“åº”æ—¶é—´**: {endpoint_result['median_response_time']*1000:.2f}ms\n")
            f.write(f"- **æœ€çŸ­å“åº”æ—¶é—´**: {endpoint_result['min_response_time']*1000:.2f}ms\n")
            f.write(f"- **æœ€é•¿å“åº”æ—¶é—´**: {endpoint_result['max_response_time']*1000:.2f}ms\n")
            f.write(f"- **95%å“åº”æ—¶é—´**: {endpoint_result['p95_response_time']*1000:.2f}ms\n")
            f.write(f"- **æ¯ç§’è¯·æ±‚æ•°(RPS)**: {endpoint_result['rps']:.2f}\n")
            
            if "stability_rating" in endpoint_result:
                f.write(f"- **å“åº”æ—¶é—´æ ‡å‡†å·®**: {endpoint_result['std_dev']*1000:.2f}ms\n")
                f.write(f"- **å˜å¼‚ç³»æ•°**: {endpoint_result['cv']:.2f}%\n")
                f.write(f"- **ç¨³å®šæ€§è¯„çº§**: {endpoint_result['stability_rating']}\n")
            
            f.write("\n")
        
        # å†™å…¥æ€§èƒ½ç“¶é¢ˆåˆ†æ
        f.write("## æ€§èƒ½ç“¶é¢ˆåˆ†æ\n\n")
        
        # æ‰¾å‡ºå“åº”æ—¶é—´æœ€é•¿çš„ç«¯ç‚¹
        slowest_endpoint = max(results["endpoint_results"].items(), key=lambda x: x[1]["avg_response_time"])
        f.write(f"- **æœ€æ…¢ç«¯ç‚¹**: {slowest_endpoint[0]} (å¹³å‡å“åº”æ—¶é—´: {slowest_endpoint[1]['avg_response_time']*1000:.2f}ms)\n")
        
        # æ‰¾å‡ºRPSæœ€ä½çš„ç«¯ç‚¹
        lowest_rps_endpoint = min(results["endpoint_results"].items(), key=lambda x: x[1]["rps"])
        f.write(f"- **ååé‡æœ€ä½ç«¯ç‚¹**: {lowest_rps_endpoint[0]} (RPS: {lowest_rps_endpoint[1]['rps']:.2f})\n\n")
        
        if "system_resources" in results:
            resources = results["system_resources"]
            if resources["max_cpu"] > 80:
                f.write("- **CPUä½¿ç”¨ç‡è¿‡é«˜**: æµ‹è¯•è¿‡ç¨‹ä¸­CPUä½¿ç”¨ç‡è¶…è¿‡80%ï¼Œå¯èƒ½æ˜¯æ€§èƒ½ç“¶é¢ˆ\n")
            if resources["max_memory"] > 80:
                f.write("- **å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜**: æµ‹è¯•è¿‡ç¨‹ä¸­å†…å­˜ä½¿ç”¨ç‡è¶…è¿‡80%ï¼Œå¯èƒ½éœ€è¦ä¼˜åŒ–å†…å­˜ä½¿ç”¨\n")
        
        # å†™å…¥ä¼˜åŒ–å»ºè®®
        f.write("\n## ä¼˜åŒ–å»ºè®®\n\n")
        
        f.write("1. **æ•°æ®åº“ä¼˜åŒ–**:\n")
        f.write("   - æ£€æŸ¥å¹¶ä¼˜åŒ–æ…¢æŸ¥è¯¢\n")
        f.write("   - ä¸ºé¢‘ç¹æŸ¥è¯¢çš„å­—æ®µæ·»åŠ ç´¢å¼•\n")
        f.write("   - è€ƒè™‘ä½¿ç”¨æ•°æ®åº“è¿æ¥æ± \n\n")
        
        f.write("2. **ç¼“å­˜ç­–ç•¥**:\n")
        f.write("   - å¯¹çƒ­ç‚¹æ•°æ®å®æ–½ç¼“å­˜\n")
        f.write("   - ä½¿ç”¨Redisç¼“å­˜æŸ¥è¯¢ç»“æœ\n")
        f.write("   - å®ç°HTTPå“åº”ç¼“å­˜\n\n")
        
        f.write("3. **ä»£ç ä¼˜åŒ–**:\n")
        f.write("   - ä¼˜åŒ–è€—æ—¶çš„ä¸šåŠ¡é€»è¾‘\n")
        f.write("   - ä½¿ç”¨å¼‚æ­¥å¤„ç†éå…³é”®è·¯å¾„æ“ä½œ\n")
        f.write("   - å‡å°‘ä¸å¿…è¦çš„æ•°æ®åº“æŸ¥è¯¢\n\n")
        
        f.write("4. **å¹¶å‘å¤„ç†**:\n")
        f.write("   - å¢åŠ åº”ç”¨å®ä¾‹æ•°\n")
        f.write("   - è°ƒæ•´Uvicornå·¥ä½œè¿›ç¨‹æ•°\n")
        f.write("   - ä½¿ç”¨è´Ÿè½½å‡è¡¡å™¨åˆ†æ•£è¯·æ±‚\n\n")
        
        f.write("5. **ç›‘æ§ä¸å‘Šè­¦**:\n")
        f.write("   - å®æ–½å®æ—¶æ€§èƒ½ç›‘æ§\n")
        f.write("   - è®¾ç½®æ€§èƒ½æŒ‡æ ‡å‘Šè­¦\n")
        f.write("   - å®šæœŸè¿›è¡Œå‹åŠ›æµ‹è¯•\n\n")
        
        f.write("## é™„ä»¶\n\n")
        f.write(f"- [æ€§èƒ½æµ‹è¯•ç»“æœCSV]({CSV_RESULT_FILE})\n")
        f.write(f"- [æ€§èƒ½æµ‹è¯•å›¾è¡¨]({CHART_RESULT_FILE})\n")
    
    print(f"âœ… å·²ç”Ÿæˆæ€§èƒ½æµ‹è¯•æŠ¥å‘Š: {REPORT_FILE}")

async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹APIæ€§èƒ½æµ‹è¯•...")
    
    # ç™»å½•è·å–ä»¤ç‰Œ
    login_success = await login()
    if not login_success:
        print("âŒ ç™»å½•å¤±è´¥ï¼Œæ— æ³•ç»§ç»­æµ‹è¯•éœ€è¦è®¤è¯çš„ç«¯ç‚¹")
    
    # æµ‹è¯•ç»“æœ
    all_results = {"endpoint_results": {}}
    
    # å¹¶å‘æµ‹è¯•æ¯ä¸ªç«¯ç‚¹
    for endpoint in TEST_ENDPOINTS:
        if endpoint["auth_required"] and not TOKEN:
            print(f"â­ï¸ è·³è¿‡éœ€è¦è®¤è¯çš„ç«¯ç‚¹: {endpoint['name']}")
            continue
        
        # 1. åŸºæœ¬è´Ÿè½½æµ‹è¯•
        result = await run_load_test(endpoint, MAX_CONCURRENT_REQUESTS, REQUEST_COUNT)
        all_results["endpoint_results"][endpoint["name"]] = result
        
        # 2. å“åº”æ—¶é—´ç¨³å®šæ€§æµ‹è¯•
        stability_result = await test_response_time_stability(endpoint)
        
        # æ›´æ–°ç»“æœ
        if "stability_rating" in stability_result:
            all_results["endpoint_results"][endpoint["name"]]["stability_rating"] = stability_result["stability_rating"]
            all_results["endpoint_results"][endpoint["name"]]["std_dev"] = stability_result["std_dev"]
            all_results["endpoint_results"][endpoint["name"]]["cv"] = stability_result["cv"]
    
    # 3. ç³»ç»Ÿèµ„æºç›‘æ§
    resources = await monitor_system_resources(duration=10)
    all_results["system_resources"] = resources
    
    # ç”Ÿæˆç»“æœå’ŒæŠ¥å‘Š
    generate_performance_charts(all_results)
    export_to_csv(all_results)
    generate_performance_report(all_results)
    
    print("\nâœ… æ€§èƒ½æµ‹è¯•å®Œæˆ! è¯·æŸ¥çœ‹æ€§èƒ½æµ‹è¯•æŠ¥å‘Šè·å–è¯¦ç»†ä¿¡æ¯ã€‚")

if __name__ == "__main__":
    asyncio.run(main()) 